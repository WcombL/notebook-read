# Elasticsearch学习

## ES 如何产生

### 大规模数据如何检索

[Elasticsearch学习](http://t.cn/RusMSlD)

当系统数据量上了10亿、100亿条的时候，我们在做系统架构的时候通常会从以下角度去考虑问题

- 用什么数据库? mysql、oracle、mongodb、hbase
- 如何解决单节点故障; lvs、F5、A10、zookeep、MQ
- 如何保证数据安全性; 热备、冷备、异地多活
- 如何解决检索难题; 数据库代理中间件 - mysql-proxy、Cobar、MaxScale
- 如何解决统计分析问题; 离线、近实时 

### 传统数据库的应对解决方案(关系型数据库)

解决要点：
- 通过主从备份解决数据安全性问题；
- 通过数据库代理中间件心跳监测，解决单节点故障问题；
- 通过代理中间件将查询语句分发到各个slave节点进行查询，并汇总结果

### 非关系型数据库的解决方案

解决要点：
- 通过副本备份保证数据安全性；
- 通过节点竞选机制解决单点问题；
- 先从配置库检索分片信息，然后将请求分发到各个节点，最后由路由节点合并并汇总结果

### 数据完全放入内存

## Elasticsearch

为解决以上问题，通常从以下方式寻找解决方法：
- 存储数据时按有序存储；
- 将数据和索引分离；
- 压缩数据；

Elasticsearch是开源高扩展的分布式全文检索引擎，可以近实时的存储、检索数据。扩展性好，可以扩展到上百台服务器，处理PB级别的数据。

Elasticsearch使用Java开发并使用Lucene做核心来实现所有索引和搜索功能，目的是通过简单的RESTful API来隐藏Lucene的复杂性

### Elasticsearh 解决问题

- 检索相关数据；
- 返回统计结果
- 速度块

### 工作原理

Elasticsearch 节点启动后，利用多播(multicast)(或者单播，如果更改了配置)寻找集群中的其它节点，并与之建立连接。

### 核心概念

- Cluster 集群
- Node 节点
- Shard 分片
    当有大量的文档时，由于内存的限制、磁盘处理能力不足、无法足够快的响应客户端请求时，一个节点可能不够。
    这种情况下，数据可以分为较小的分片。每个分片放在不同的服务器上。当你查询的索引分布在多个分片上时，ES会把查询发送给每个相关的分片，并将结果组合在一起，而应用程序并不知道分片的存在。即这个过程对用户来说是透明的
- Replia 副本
    为提高查询吞吐量或实现高可用性，可以使用分片副本。副本是一个分片的精确复制，每个分片可以有0或多个副本。
    ES中可以有许多相同的分片，其中之一被选择更改索引操作，这个特殊分片被称为主分片
    当主分片丢失时，集群将副本提升为新的主分片
- 全文检索
    全文检索检索对一篇文章进行索引，可以根据关键字搜索。
    全文索引检索把内容根据词的意义进行分词，然后分别创建索引

ELK = elasticsearch + logstash + kibana

### Elasticsearch特点和优势

- 分布式实时文件存储，可以将每一个字段存入索引，使其可以被检索到
- 实时分析的分布式搜索引擎
- 可扩展性强
- 支持插件，分词插件、同步插件、Hadoop插件、可视化插件等

## Elasticsearch 配置清单

### 节点配置
默认情况下，集群中的每个节点都可以处理Http请求和集群节点的数据传输

集群中的所有的节点都知道集群中其他所有的节点，可以将客户端请求转发到适当的节点

主节点(master):
node.master: true
node.data: false
主节点负责轻量级的集群范围的操作。例如：
- 创建或删除索引
- 跟踪那些节点是集群的一部分
- 决定要分配给那些节点的分片。
拥有稳定的主节点对集群健康很重要

数据节点(data):
node.master: false
node.data: true
数据节点保存包含索引文档的分片。
数据节点处理：
- 与CRUD、搜索和聚合相关的数据相关操作
- 这些操作是I/O、内存和CPU密集型
- 如果监控这些资源超载，就需要添加更多的数据节点

客户端/路由节点(client):
node.master: false
node.data: false
路由节点：
- 处理路由请求
- 处理搜索聚合节点
- 分发批量索引请求

> 默认情况下，节点同时是主节点和数据节点，这适合小集群（3个节点）；大于3个节点后，分离主节点和数据节点变得非常重要

### 线程池

尽量不要动线程池这个配置，如果要动，建议改为： 
int((核心数*3)/2)＋ 1
同时满足：不允许bulk和’indexing’线程池的大小大于CPU内核数

举例：24核处理器，检索服务器是24核，所以：线程池的大小=(24*3)/2+1=37
同时要满足cpu核数为24。37和24取最小值，应该选择24

默认的队列大小是1000

### 配置堆内存

Elasticsearch 默认安装后设置的堆内存是 1 GB

方式一：export ES_HEAP_SIZE=4g
方式二：./bin/elasticsearch -Xmx4g -Xms4g
方式三：5.x+建议使用
修改jvm.options配置文件
-Xms4g
-Xmx4g
> 确保堆内存最小值（ Xms ）与最大值（ Xmx ）的大小是相同的，防止程序在运行时改变堆内存大小， 这是一个很耗系统资源的过程

> 最大可分配堆内存大小为： 32GB与当前ES宿主机内存二者的最小值

ES宿主机内存：128GB，可供分配的堆内存：32GB。（建议31GB） 
ES宿主机内存：32GB，可供分配的堆内存：16GB。

### 禁止swapping操作

bootstrap.memory_lock: true

> 内存交换到磁盘对服务器性能来说是致命的

5.x以前叫做 bootstrap.mlockall

### 配置文件描述符数目

需要在ES启动用户下进行配置

- 设置环境变量
    vim /etc/profile 
    增加 ulimit -n 65535 用以设定同一时间打开的文件数的最大值为65535
    source /etc/profile 使得命令生效
- 修改limits.conf配置文件
    /etc/security/limits.conf
    增加
    * soft nofile 65536
    * hard nofile 65536
    用来限制打开文件数65535
- 使用ulimit -a 查看是否修改成功
- 
> Elasticsearch 在节点和 HTTP 客户端之间进行通信也使用了大量的套接字（注：sockets）。 所有这一切都需要足够的文件描述符

### 修改最大映射数量MMP

Elasticsearch 对各种文件混合使用了 NioFs(非阻塞文件系统)和MMapFs(内存映射文件系统)

确保你配置的最大映射数量，以便有足够的虚拟内存可用于 mmapped 文件

暂时设置
sysctl -w vm.max_map_count=262144

在 /etc/sysctl.conf 通过修改 vm.max_map_count 永久设置
confvm.max_map_count=262144

### 5.x之后更新配置

新增节点类型Ingest节点/提取节点

Ingest的用途
- Ingest节点和集群中的其他节点一样，但是它能够创建多个处理器管道，用以修改传入文档。类似 最常用的Logstash过滤器已被实现为处理器。
- Ingest节点 可用于执行常见的数据转换和丰富。 处理器配置为管道。 在写入时，Ingest Node有20个内置处理器，例如grok，date，gsub，小写/大写，删除和重命名等。
- 在批量请求或索引操作之前，Ingest节点拦截请求，并对文档进行处理

### 节点组合类型配置

一个节点的缺省配置是：主节点+数据节点两属性为一身。对于3-5个节点的小集群来讲，通常让所有节点存储数据和具有获得主节点的资格。你可以将任何请求发送给任何节点，并且由于所有节点都具有集群状态的副本，它们知道如何路由请求。

通常只有较大的集群才能开始分离专用主节点、数据节点。 对于许多用户场景，路由节点根本不一定是必需的。

专用协调节点（也称为client节点或路由节点）从数据节点中消除了聚合/查询的请求解析和最终阶段，并允许他们专注于处理数据。 在多大程度上这对集群有好处将因情况而异。 通常我会说，在查询大量使用情况下路由节点更常见。

## Elasticsearch 检索技巧

## Elasticsearch 分片设置

[索引分片设置](http://t.cn/R3hI8KR)

引申问题：
- 应该有多少分片
- 每个分片应该有多大

### 概念

- 刷新：当数据写入分片时，它会定期地发布到磁盘上的新的不可变的Lucene段中，此时它可用于查询。——这被称为刷新
- 合并：随着分段数（segment）的增长，这些segment被定期地整合到较大的segments。 这个过程被称为合并（merging）

由于所有分段都是不可变的， 因为新的合并分段需要创建，旧的分段将被删除 ，这意味着所使用的磁盘空间通常在索引时会波动。 合并可能资源相当密集，特别是在磁盘I/O方面。

分片是Elasticsearch在集群周围分发数据的单位。 Elasticsearch在重新平衡数据时(例如 发生故障后)移动分片的速度 取决于分片的大小和数量以及网络和磁盘性能。

> 避免有非常大的分片，因为大的分片可能会对集群从故障中恢复的能力产生负面影响。 对于多大的分片没有固定的限制，但是分片大小为50GB通常被界定为适用于各种用例的限制

### 索引有效期

由于分段是不可变的
- 更新文档：Elasticsearch查找到现有文档，然后标记为已删除，并添加更新的版本。
- 删除文档：找到文档并将其标记为已删除。因此删除的文档将继续占有磁盘空间和一些系统资源，直到被合并，这将消耗    大量的系统资源

> Elasticsearch允许从文件系统中直接整个索引。这是删除数据最有效的方式

尽可能使用基于时间的索引来管理数据。根据保留期（retention period，可以理解成有效期）将数据分组。基于时间的索引还可以轻松地随时间改变主分片和副本分片的数量

### 索引与分片

对于每个索引，其映射和状态信息都是存储在集群状态中。这些信息保存在内存中以便快速访问。因此如果有大量索引，可能导致大的集群状态。所有更新集群状态为了在集群中保证一致性，需要通过单线程完成，因此更新速度将变慢。

> 为减少索引数量并避免大的乃至非常庞大的映射，考虑将相同索引结构的数据存储在相同的索引中。在每个索引的索引数量和映射大小之间找到一个很好的平衡点这很重要。

应该有多少个分片
答： 每个节点的分片数量保持在低于每1GB堆内存对应集群的分片在20-25之间

分片应该有多大
答：分片大小为50GB通常被界定为适用于各种用例的限制


## Elasticsearch 单字段支持最大字符数

- 问题1：设置为keyword类型的字段，插入很长的大段内容后，报字符超出异常，无法插入。
- 问题2：检索超过ignore_above设定长度的字段后，无法返回结果。

> keyword类型的最大支持的长度为——32766个UTF-8类型的字符。也就是说term精确匹配的最大支持的长度为32766个UTF-8个字符

text类型：支持分词、全文检索，不支持聚合、排序操作。适合大字段存储

keyword类型：支持精确匹配，支持聚合、排序操作。适合精准字段匹配

- ES5.X版本以后，keyword支持的最大长度为32766个UTF-8字符，text对字符长度没有限制。
- 设置ignore_above后，超过给定长度后的数据将不被索引，无法通过term精确匹配检索返回结果。


## join类型

解决：一对多、多对多的数据存储和实现

借助父子关系，实现类似Mysql中多表关联的操作

## Elasticsearch 6.x 去重

- 统计计数需要借助ES聚合功能结合cardinality实现
- 去重显示结果两种方式：
    - 使用字段聚合+top_hits聚合方式
    - 使用collapse折叠功能

去重统计
```json
{
    "size": 0, 
    "aggs": {
        "books_count": {
            "cardinality": {
                "field": "title.keyword"
            }
        }
    }
}
```

## Elasticsearch 堆内存

### 堆内存配置建议

- 将最小堆大小(Xms)和最大堆大小(Xmx)设置为彼此相等
- Elasticsearch可用的堆越多，可用于缓存的内存就越多。但请注意，太多的堆内存可能会使你长时间来讲收集暂停
- 将Xmx设置为不超过物理内存的50%，以确保有足够的物理内存留给内核文件系统缓存
- 不要将Xmx设置为JVM超过32GB
- 宿主机内存大小的一半和31GB，取最小值

### 堆内存为什么不能超过物理机内存的一半

堆对于Elasticsearch绝对重要。
它被许多内存数据结构用来提供快速操作。但还有另外一个非常重要的内存使用者：Lucene。

Lucene旨在利用底层操作系统来缓存内存中的数据结构。 Lucene段(segment)存储在单个文件中。
因为段是一成不变的，所以这些文件永远不会改变。
这使得它们非常容易缓存，并且底层操作系统将愉快地将热段（hot segments）保留在内存中以便更快地访问。
这些段包括倒排索引（用于全文搜索）和文档值（用于聚合）。

Lucene的性能依赖于与操作系统的这种交互。但是如果你把所有可用的内存都给了Elasticsearch的堆，
那么Lucene就不会有任何剩余的内存。这会严重影响性能。

标准建议是将可用内存的50％提供给Elasticsearch堆，而将其他50％空闲。它不会被闲置; 
Lucene会高兴地吞噬掉剩下的东西。

如果您不在字符串字段上做聚合操作（例如，您不需要fielddata），则可以考虑进一步降低堆。
堆越小，您可以从Elasticsearch（更快的GC）和Lucene（更多内存缓存）中获得更好的性能。

### 堆内存为什么不能超过32GB

在Java中，所有对象都分配在堆上并由指针引用。普通的对象指针（OOP）指向这些对象，
传统上它们是CPU本地字的大小：32位或64位，取决于处理器。

对于32位系统，这意味着最大堆大小为4 GB。对于64位系统，堆大小可能会变得更大，
但是64位指针的开销意味着仅仅因为指针较大而存在更多的浪费空间。
并且比浪费的空间更糟糕，当在主存储器和各种缓存（LLC，L1等等）之间移动值时，较大的指针消耗更多的带宽。

Java使用称为压缩oops的技巧来解决这个问题。而不是指向内存中的确切字节位置，指针引用对象偏移量。
这意味着一个32位指针可以引用40亿个对象，而不是40亿个字节。最终，这意味着堆可以增长到约32 GB的物理尺寸，
同时仍然使用32位指针。

一旦你穿越了这个神奇的〜32 GB的边界，指针就会切换回普通的对象指针。每个指针的大小增加，使用更多的CPU内存带
宽，并且实际上会丢失内存。实际上，在使用压缩oops获得32 GB以下堆的相同有效内存之前，需要大约40-50 GB的分配
堆。

以上小结为：即使你有足够的内存空间，尽量避免跨越32GB的堆边界。
否则会导致浪费了内存，降低了CPU的性能，并使GC在大堆中挣扎。

### 如果已有大内存机器如何使用

- 你是否主要进行全文搜索？

考虑给Elasticsearch提供4-32 GB，并让Lucene通过操作系统文件系统缓存使用剩余的内存。
所有内存都会缓存段，并导致快速全文搜索。

- 你在做很多排序/聚合？

大部分聚合数字，日期，地理位置和not_analyzed字符串？你很幸运，你的聚合将在内存缓存的文档值上完成！

从4-32 GB的内存中给Elasticsearch一个地方，剩下的让操作系统在内存中缓存doc值。

-  你是否对分析过的字符串进行了很多排序/聚合（例如对于字标记或SigTerms等）？
    -  不幸的是，这意味着你需要fielddata，这意味着你需要堆空间。
    -  考虑在一台机器上运行两个或多个节点，而不是一个节点数量巨大的RAM。
    -  尽管如此，仍然坚持50％的规则。

建议：
- 因此，如果您的机器具有128 GB的RAM，请运行两个节点，每个节点的容量低于32 GB。
    这意味着小于64 GB将用于堆，而Lucene将剩余64 GB以上。
- 如果您选择此选项，请在您的配置中设置cluster.routing.allocation.same_shard.host：true。
    这将阻止主副本分片共享同一台物理机（因为这会消除副本高可用性的好处）

### 堆内存优化建议

方式一：最好的办法是在系统上完全禁用交。
这可以暂时完成：
```
sudo swapoff -a
```
要永久禁用它，你可能需要编辑你的/ etc / fstab

方式二：控制操作系统尝试交换内存的积极性
如果完全禁用交换不是一种选择，您可以尝试降低swappiness。该值控制操作系统尝试交换内存的积极性。
这可以防止在正常情况下交换，但仍然允许操作系统在紧急内存情况下进行交换。

对于大多数Linux系统，这是使用sysctl值配置的：
```
vm.swappiness = 1
```
1的swappiness优于0，因为在某些内核版本上，swappiness为0可以调用OOM杀手

方式三：mlockall允许JVM锁定其内存并防止其被操作系统交换
如果两种方法都不可行，则应启用mlockall。文件。这允许JVM锁定其内存并防止其被操作系统交换。在你的elasticsearch.yml中，设置这个：
```
bootstrap.mlockall：true
```

事实上，给ES分配的内存有一个魔法上限值26GB，
这样可以确保启用zero based Compressed Oops，这样性能才是最佳的。

[参考文章](https://www.elastic.co/blog/a-heap-of-trouble)